{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7409c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c9f38ce",
   "metadata": {},
   "source": [
    "Class Datapoint contains acceleration, magnitude and time values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98fa1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Datapoint contains magnitude and corresponding time values \n",
    "\n",
    "# Define a class named 'DataPoint'\n",
    "class DataPoint:\n",
    "    def __init__(self, mag, time):\n",
    "        self.mag = mag  # Initialize the magnitude attribute\n",
    "        self.time = time   # Initialize the time attribute\n",
    "        \n",
    "    def __str__(self):\n",
    "        # Generate a string representation of the DataPoint\n",
    "        ret = f\"Acceleration magnitude is {self.mag} and time is {self.time}\"\n",
    "        return ret\n",
    "    \n",
    "    # Method to retrieve the time value of the DataPoint\n",
    "    def getTime(self):\n",
    "        return self.time \n",
    "    \n",
    "    # Method to set the time value of the DataPoint\n",
    "    def setTime(self, time):\n",
    "        self.time = time\n",
    "    \n",
    "     # Method to retrieve the magnitude value of the DataPoint\n",
    "    def getMagnitude(self):\n",
    "        return self.mag\n",
    "    \n",
    "    # Method to set the magnitude value of the DataPoint\n",
    "    def setMagnitude(self, mag):\n",
    "        self.mag = mag"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a19f60e7",
   "metadata": {},
   "source": [
    "1. Pre-Processing Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05a9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pre-processing stage\n",
    "\n",
    "def PreProcessingStage(data, samplingPeriod = 60):\n",
    "    '''\n",
    "    First stage of step counting\n",
    "    -----------------------------\n",
    "        This stage is responsible for computing the magnitude of the triaxial accelerometer signal\n",
    "        ensuring a constant sampling frequency by means of linear interpolation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        pandas dataframe containing accelerometer values viz. acc_x, acc_y, acc_z \n",
    "        and corresponding unix-timestamp\n",
    "    samplingPeriod : float, optional\n",
    "        The default is 60.\n",
    "        sampling period is in milli second (15 Hz) to interpolate values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ppData : list\n",
    "        the output list  of preprocessing stage which contains DataPoints.\n",
    "    '''    \n",
    "    ppData = []  # List to append the the return value of class data point i.e Datapoint 1 - Magnitude and corr time\n",
    "    DataLen = len(data[\"time\"]) # total number of data points in the data set\n",
    "    for i in range(DataLen):\n",
    "        acc_mag = ((data[\"acc_x\"][i] ** 2 + data[\"acc_y\"][i] ** 2 + data[\"acc_z\"][i] **2)** 0.5) # acceleration magnitude\n",
    "        cur_time = data[\"time\"][i]\n",
    "        dp = DataPoint(acc_mag, cur_time)\n",
    "        ppData.append(dp)\n",
    "    #print('preprocessing stage:', ppData)\n",
    "    return ppData        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "6591968b",
   "metadata": {},
   "source": [
    "2. Filter Stage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee089bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Filter Stage \n",
    "\n",
    "def FilterStage(ppData, filterLength = 13, filterSTD = 0.35):\n",
    "    '''\n",
    "    Second stage of step counting\n",
    "    -----------------------------\n",
    "        In order to reduce the noise level, algorithm implements a \n",
    "        finite impulse response (FIR) low-pass filter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ppData : list\n",
    "        This ppData list is a output of preprocessing stage which contains DataPoints\n",
    "    filterLength : int, optional\n",
    "        The default is 13.\n",
    "        length of window for a filter\n",
    "    filterSTD : float, optional\n",
    "        The default is 0.35.\n",
    "        std dev for generating filter coefficients\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    smoothData : list\n",
    "        smoothened data.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    midPoint = int(filterLength/2)\n",
    "    filterVals = GenerateFilterCoef(filterLength, filterSTD) # Generate filter coeff\n",
    "    filterSum = sum(filterVals)\n",
    "    inputQueue = ppData[:] #shallow copy\n",
    "    smoothData = [] # output of filter stage\n",
    "    active = True\n",
    "    window = [] #list contains data point values\n",
    "    \n",
    "    while(active):\n",
    "        window.append(inputQueue.pop(0))\n",
    "        if(len(inputQueue) == 0):\n",
    "            active = False\n",
    "            \n",
    "        if(len(window) == filterLength):\n",
    "            temp = [v1*v2.getMagnitude() for v1,v2 in zip(filterVals, window)]\n",
    "            acc_new_mag = sum(temp)/filterSum\n",
    "            dp = DataPoint(acc_new_mag, window[midPoint].getTime())\n",
    "            smoothData.append(dp)\n",
    "            window.pop(0)\n",
    "    #print('filter stage:', smoothData)      \n",
    "    return smoothData\n",
    "\n",
    "def GenerateFilterCoef(filterLength = 13, filterSTD = 0.35):\n",
    "    \n",
    "    '''\n",
    "    Generate the filter coefficients based on the filter length and std dev\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filterLength : int, optional\n",
    "        length of filter. The default is 13.\n",
    "    filterSTD : float, optional\n",
    "        std dev. The default is 0.35.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    FIR_Vals : list\n",
    "        filter coefficients.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    FIR_Vals = [math.pow(math.e, -0.5*math.pow((i - (filterLength - 1)/2) / \n",
    "                 (filterSTD * (filterLength - 1)/2), 2)) for i in range(filterLength)]\n",
    "    \n",
    "    return FIR_Vals\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "92207134",
   "metadata": {},
   "source": [
    "3. Scoring Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7a5dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Scoring Stage\n",
    "\n",
    "def ScoringStage(smoothData, windowSize = 35):\n",
    "    \n",
    "    '''\n",
    "    Third stage of step counting\n",
    "    ----------------------------\n",
    "        The function of the scoring stage is to evaluate the peakiness of a given \n",
    "        sample. The result of this stage should increase the magnitude of any \n",
    "        peaks, making them more evident for the subsequent peak detection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smoothData : list\n",
    "        list containing smoothened datapoint values\n",
    "    windowSize : int, optional\n",
    "        window size for score peak calculation. The default is 35.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    peakScoreData : list\n",
    "        output of scoring stage.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    midPoint = int(windowSize/2) #Mid point of window\n",
    "    inputQueue = smoothData[:] # shallow copy\n",
    "    peakScoreData = [] \n",
    "    window = [] #list containing magnitude values\n",
    "    active = True\n",
    "    \n",
    "    while(active):\n",
    "        window.append(inputQueue.pop(0))\n",
    "        if(len(inputQueue) == 0):\n",
    "            active = False\n",
    "            \n",
    "        if(len(window) == windowSize):\n",
    "            diffLeft = 0\n",
    "            diffRight = 0\n",
    "            # calculate diffleft and diffright based on the algorithm\n",
    "            for i in range(midPoint):\n",
    "                diffLeft += window[midPoint].getMagnitude() - window[i].getMagnitude();\n",
    "            for J in range(midPoint, windowSize):\n",
    "                diffRight += window[midPoint].getMagnitude() - window[J].getMagnitude();\n",
    "        \n",
    "            # Calculate the score and append to the output list\n",
    "            score = (diffRight + diffLeft) / (windowSize - 1)\n",
    "            dp = DataPoint(score, window[midPoint].getTime())\n",
    "            peakScoreData.append(dp)\n",
    "            # Pop out the oldest point from the window\n",
    "            window.pop(0)\n",
    "            \n",
    "    #print('scoring stage:', peakScoreData)\n",
    "        \n",
    "    return peakScoreData\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a4f87",
   "metadata": {},
   "source": [
    "Detection Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec9103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Detection Stage\n",
    "\n",
    "def DetectionStage(peakScoreData, threshold = 1.2):\n",
    "    \n",
    "    '''\n",
    "    Fourth stage of step counting\n",
    "    -----------------------------\n",
    "        This stage identifies potential candidate peaks to be associated with a \n",
    "        step by statistically detecting outliers. \n",
    "        As the algorithm processes the signal, it keeps track of a running mean \n",
    "        and standard deviation. These two quantities are used to determine \n",
    "        whether any given sample is an outlier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    peakScoreData : list\n",
    "        list containing peakiness values.\n",
    "    threshold : float, optional\n",
    "        detection threshold. The default is 1.2 assuming the sampling frequency is 100Hz.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    outputQueue : list\n",
    "        output list containing DataPoints.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    inputQueue = peakScoreData[:] # Shallow copy\n",
    "    outputQueue = []\n",
    "    # initial parameters\n",
    "    active = True\n",
    "    count = 0\n",
    "    acc_mean = 0\n",
    "    acc_std = 0\n",
    "    \n",
    "    while(active):\n",
    "        dp = inputQueue.pop(0)\n",
    "        if(len(inputQueue) == 0):\n",
    "            active = False\n",
    "            # dp = DataPoint(0, 0)\n",
    "            # outputQueue.append(dp)\n",
    "            # continue\n",
    "        count +=1\n",
    "        o_mean = acc_mean\n",
    "        \n",
    "        # Update calculations of mean and std deviation\n",
    "        if(count == 1):\n",
    "            acc_mean = dp.getMagnitude()\n",
    "            acc_std = 0\n",
    "        elif(count == 2):\n",
    "            acc_mean = (acc_mean + dp.getMagnitude())/2\n",
    "            acc_std = (((dp.getMagnitude() - acc_mean)**2 + (o_mean - acc_mean)**2 ) ** 0.5)/2            \n",
    "        else:\n",
    "            acc_mean = (dp.getMagnitude() + (count - 1)*acc_mean)/count\n",
    "            acc_std = (((count - 2) * (acc_std**2)/(count-1)) + (o_mean - acc_mean)**2 + ((dp.getMagnitude() - acc_mean) ** 2)/count)**0.5\n",
    "        \n",
    "        # Once we have enough data points to have a reasonable mean/standard deviation, start detecting\n",
    "        if(count >= 1): #Min data points to be counted is 1 data point\n",
    "            if ((dp.getMagnitude() - acc_mean) > acc_std * threshold):\n",
    "                # This is peak\n",
    "                outputQueue.append(dp)\n",
    "    \n",
    "    #print('detection stage:', outputQueue)\n",
    "    return outputQueue\n",
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "39c100dd",
   "metadata": {},
   "source": [
    "Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f76dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Post-processing\n",
    "\n",
    "def PostProcessStage(peakData, timeThreshold=200):\n",
    "    '''\n",
    "    Fifth Stage of Step Counting\n",
    "    ----------------------------\n",
    "        handles false positives from the detection stage by having a sliding \n",
    "        window of fixed size t_window and selecting the higher peak within the window\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    peakData : list\n",
    "        this list is output of detection stage.\n",
    "    timeThreshold : float/int, optional\n",
    "        The default is 200. Time in millisecond\n",
    "        By considerng human can walk max 5 steps in a sec.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    steps : int\n",
    "        number of steps detected by algorithm\n",
    "    outputQueue : list\n",
    "        list of datapoints for which step is detected.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    steps = 0 # number of steps detected\n",
    "    inputQueue = peakData[:]\n",
    "    outputQueue = []\n",
    "    current = peakData[0]\n",
    "    active = True\n",
    "    while(active):\n",
    "        dp = inputQueue.pop(0)\n",
    "        if(len(inputQueue) == 0):\n",
    "            active = False\n",
    "            # dp = DataPoint(0, 0)\n",
    "            # End of stage\n",
    "            # continue\n",
    "        \n",
    "        if ((dp.getTime() - current.getTime()) > timeThreshold):\n",
    "            # If the time difference exceeds the threshold, we have a confirmed step\n",
    "            current = dp\n",
    "            steps += 1\n",
    "            outputQueue.append(dp)\n",
    "        else:\n",
    "            if (dp.getMagnitude() > current.getMagnitude()):\n",
    "                # Keep the point with the largest magnitude.\n",
    "                current = dp\n",
    "    \n",
    "    return steps, outputQueue"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b31548c",
   "metadata": {},
   "source": [
    "Read the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db4b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file\n",
    "\n",
    "def readCSVFile(data_files):\n",
    "    \n",
    "    '''\n",
    "    read the csv file present at current path\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_files = list\n",
    "        list of all data sets\n",
    "    data : DataFrame\n",
    "        pandas dataframe contain accelerometer and corr time values \n",
    "    sample_time: int\n",
    "        time for one accelerometer data point\n",
    "    sampli_frequency : float\n",
    "        data collection frequency\n",
    "    threshold:float\n",
    "        detection threshold. default is 1.2\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    raw_DF : DataFrame\n",
    "        pandas dataframe which contains all csv data.\n",
    "\n",
    "    '''\n",
    "    for file in data_files:\n",
    "        data = pd.read_csv(file, header=None)\n",
    "        file_name = file.split('_')\n",
    "        data = data.iloc[:,-8:]\n",
    "        data.columns = ['acc_x', 'acc_y', 'acc_z','a','b','c','constant', 'time']\n",
    "        sample_time = int((data['time'][1]) - (data['time'][0])) #calculate actual sampli time\n",
    "        sample_frequency = float(1/(sample_time * 1e-3)) #calculate actual sampling frequency\n",
    "        thresholdvalue = float((1.2 * sample_frequency) / 100) #threshold value considering 1.2 is std value for 100Hz\n",
    "        acc_value = data['acc_x'][0] \n",
    "        if acc_value >= -3000:   # Assumed threshold value to compensate tighteness or lossness of flexitail\n",
    "            skipfilter = True\n",
    "        else:\n",
    "            skipfilter = False\n",
    "        steps, d1 = RunAlgo(data,samplingPeriod = sample_time, SKIPFILTER = skipfilter, filterlength = 13, filterSTD = 0.35,  windowSize = 35, threshold = thresholdvalue, timeThreshold = 200)\n",
    "        \n",
    "        start_time = datetime.fromtimestamp(int(str(data['time'].iloc[0])[0:-3])).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        end_time = datetime.fromtimestamp(int(str(data['time'].iloc[-1])[0:-3])).strftime('%H:%M:%S')\n",
    "        if len(file_name) <= 4:\n",
    "            print( start_time, end_time, file_name[3], ':', steps)\n",
    "        else:\n",
    "            print( start_time, end_time, file_name[4], file_name[6], ':', steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78854f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run algorithm\n",
    "\n",
    "def RunAlgo(data, samplingPeriod = 60, \\\n",
    "            SKIPFILTER = False, filterlength = 13, filterSTD =0.35, \\\n",
    "            windowSize = 35, threshold = 1.2, timeThreshold = 200) :\n",
    "    \n",
    "    '''\n",
    "    Implement the oxford java step counter algorithm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        input data required for preprocessing stage.\n",
    "    samplingPeriod : float, optional\n",
    "        Time period to interpolate data points. The default is 60 millisecond.\n",
    "    SKIPFILTER : bool, optional\n",
    "        wheather filter stage should be executed or not. The default is False.\n",
    "    filterLength : int, optional\n",
    "        length of filter window. The default is 13.\n",
    "    filterSTD : float, optional\n",
    "        std dev for generating filter coefficients. The default is 0.35.\n",
    "    windowSize : int, optional\n",
    "        length of window in scoring stage. The default is 35.\n",
    "    threshold : float, optional\n",
    "        threshold required for detection stage. The default is 1.2.\n",
    "    timeThreshold : float/int, optional\n",
    "        time in millisecond, used to detect steps. The default is 200.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    steps : int\n",
    "        number of steps.\n",
    "    detectedStepsList : list\n",
    "        datapoints for which step is detected.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    ppData = PreProcessingStage(data)\n",
    "    \n",
    "    if (not SKIPFILTER):\n",
    "        smoothData = FilterStage(ppData)\n",
    "    else:\n",
    "        smoothData = ppData\n",
    "    peakScoreData = ScoringStage(smoothData, windowSize)\n",
    "    peakData = DetectionStage(peakScoreData, threshold)\n",
    "    steps, detectedStepsList = PostProcessStage(peakData, timeThreshold)\n",
    "    return steps, detectedStepsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faf658b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    # Data sets for algorithm validation\n",
    "    data_files = ['1663927235497_Max_walking_5hz-50steps.csv', '1666178020224_samsung_SM-A528B_FT26A_5Hz_walking_50-steps.csv', \\\n",
    "                  '1666177837406_samsung_SM-A528B_FT26A_5Hz_walking_100-steps.csv','1663927276636_Max_walking_5hz-100steps.csv', \\\n",
    "                  '1663927357038_Max_walking_5hz-150steps-fast.csv', '1663926837642_Max_walking_15hz-50steps.csv', \\\n",
    "                  '1666177915040_samsung_SM-A528B_FT26A_15Hz_walking_50-steps.csv', '1666177951490_samsung_SM-A528B_FT26A_15Hz_walking_100-steps.csv', \\\n",
    "                  '1667398754709_samsung_SM-A528B_FT91A_5Hz_walking_20steps.csv', '1667398773370_samsung_SM-A528B_FT91A_5Hz_walking_10-steps.csv', \\\n",
    "                  '1667398789600_samsung_SM-A528B_FT91A_5Hz_walking_15-steps.csv', '1667398820924_samsung_SM-A528B_FT91A_5Hz_walking_25steps.csv', \\\n",
    "                  '1667398842757_samsung_SM-A528B_FT91A_5Hz_walking_20steps.csv', '1667398861596_samsung_SM-A528B_FT91A_5Hz_walking_5-steps.csv', \\\n",
    "                  '1667398875681_samsung_SM-A528B_FT91A_5Hz_walking_4-steps.csv', '1667398884877_samsung_SM-A528B_FT91A_5Hz_walking_25-steps.csv', \\\n",
    "                  '1667398919949_samsung_SM-A528B_FT91A_5Hz_walking_50-steps.csv', '1667398956068_samsung_SM-A528B_FT91A_5Hz_walking_100-steps.csv', \\\n",
    "                  '1667399029417_samsung_SM-A528B_FT91A_15Hz_walking_5-steps.csv', '1667399038177_samsung_SM-A528B_FT91A_15Hz_walking_15-steps.csv', \\\n",
    "                  '1667399051107_samsung_SM-A528B_FT91A_15Hz_walking_100-steps.csv', '1667399179387_samsung_SM-A528B_FT91A_15Hz_walking_66-steps.csv']\n",
    "    readCSVFile(data_files) # Read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41c1a352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-23 15:30:35 15:31:13 5hz-50steps.csv : 38\n",
      "2022-10-19 16:43:40 16:44:12 5Hz 50-steps.csv : 52\n",
      "2022-10-19 16:40:37 16:41:41 5Hz 100-steps.csv : 111\n",
      "2022-09-23 15:31:16 15:32:25 5hz-100steps.csv : 101\n",
      "2022-09-23 15:32:37 15:34:20 5hz-150steps-fast.csv : 152\n",
      "2022-09-23 15:23:57 15:24:47 15hz-50steps.csv : 53\n",
      "2022-10-19 16:41:55 16:42:30 15Hz 50-steps.csv : 49\n",
      "2022-10-19 16:42:31 16:43:30 15Hz 100-steps.csv : 100\n",
      "2022-11-02 19:49:14 19:49:31 5Hz 20steps.csv : 20\n",
      "2022-11-02 19:49:33 19:49:45 5Hz 10-steps.csv : 3\n",
      "2022-11-02 19:49:49 19:50:03 5Hz 15-steps.csv : 18\n",
      "2022-11-02 19:50:20 19:50:41 5Hz 25steps.csv : 26\n",
      "2022-11-02 19:50:42 19:51:00 5Hz 20steps.csv : 20\n",
      "2022-11-02 19:51:01 19:51:11 5Hz 5-steps.csv : 0\n",
      "2022-11-02 19:51:15 19:51:23 5Hz 4-steps.csv : 2\n",
      "2022-11-02 19:51:24 19:51:43 5Hz 25-steps.csv : 23\n",
      "2022-11-02 19:51:59 19:52:35 5Hz 50-steps.csv : 53\n",
      "2022-11-02 19:52:36 19:53:43 5Hz 100-steps.csv : 103\n",
      "2022-11-02 19:53:49 19:53:57 15Hz 5-steps.csv : 4\n",
      "2022-11-02 19:53:58 19:54:10 15Hz 15-steps.csv : 13\n",
      "2022-11-02 19:54:11 19:55:15 15Hz 100-steps.csv : 117\n",
      "2022-11-02 19:56:19 19:57:02 15Hz 66-steps.csv : 70\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
